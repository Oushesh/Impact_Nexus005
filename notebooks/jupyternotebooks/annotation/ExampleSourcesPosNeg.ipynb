{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/22-02-22_annotation/Concept Impact Eval - Comparison.tsv', sep=\"\\t\", na_values=[''], keep_default_na=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['GOLD', 'MODEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GOLD'] = df['GOLD'].apply(lambda x: {'POSITIVE': 1, 'NULL': 0, 'NEGATIVE': -1}[x])\n",
    "df['MODEL'] = df['MODEL'].apply(lambda x: {'POSITIVE': 1, 'NULL': 0, 'NEGATIVE': -1}[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129600230913552"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# stan_mikael = df.dropna(subset=['STAN', 'MIKAEL'])\n",
    "# cohen_kappa_score(stan_mikael['STAN'], stan_mikael['MIKAEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([14, 24, 26, 27, 30, 31, 32, 34, 37, 66, 67, 69], dtype='int64')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stan_mikael[(stan_mikael['MIKAEL'] != stan_mikael['STAN']) ][['Text', 'Company concepts', 'Impact concepts', 'STAN', 'MIKAEL']].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.75      0.60      0.66       134\n",
      "        NULL       0.26      0.07      0.11        68\n",
      "    POSITIVE       0.71      0.98      0.82       206\n",
      "\n",
      "    accuracy                           0.70       408\n",
      "   macro avg       0.57      0.55      0.53       408\n",
      "weighted avg       0.65      0.70      0.65       408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df['GOLD'], df['MODEL'], target_names=['NEGATIVE', 'NULL', 'POSITIVE', ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a01f96bacd60138fda158296e46c63e862f79e288a616d9fda278940a44f53f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
