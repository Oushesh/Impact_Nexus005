{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import boto3\n",
        "from requests_aws4auth import AWS4Auth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('../..')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agg_query = {\n",
        "    \"query\": {\n",
        "        \"bool\": {\n",
        "            \"should\": [\n",
        "                {\"term\": {\"predictions.sustainability_potential\": \"SOLUTION\"}},\n",
        "                {\"term\": {\"predictions.sustainability_potential\": \"PROBLEM+SOLUTION\"}},\n",
        "            ],\n",
        "        }\n",
        "    },\n",
        "    \"size\": 1000,\n",
        "    \"aggs\": {\n",
        "        \"sources\": {\n",
        "            \"terms\": {\"field\": \"scraper\"},\n",
        "            \"aggs\": {\n",
        "                \"documents\": {\n",
        "                    \"terms\": {\n",
        "                        \"field\": \"document_id\",\n",
        "                        \"size\": 2\n",
        "                    },\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "    },\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts import opensearch_connection\n",
        "paragraphs = opensearch_connection.opensearch_iterate_all_documents('paragraphs-*', agg_query, scroll_timeout=\"1m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "paragraphs = list(paragraphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(paragraphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame([{**par['_source'], id: par['_id']} for par in paragraphs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['n_key_tok'] = df.n_keywords/df.n_tokens\n",
        "df['n_ent_tok'] = df.entities.apply(len)/df.n_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop_duplicates('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "OUT_PATH = Path(\"datasets/intermediate/labeling/X_paragraph_sentences.tsv\")\n",
        "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "rows = []\n",
        "for row in df.itertuples(index=False):\n",
        "    par_row = {\n",
        "        \"SCRAPER\": row.scraper,\n",
        "        \"TITLE\": row.title,\n",
        "        \"URL\": row.url,\n",
        "        \"ID\": row.id,\n",
        "        \"PAR_IND\": row.par_ind,\n",
        "        \"N_KEYWORDS/TOKEN\": row.n_key_tok,\n",
        "        \"SENT_IND\": -1,\n",
        "    }\n",
        "    par_row |= {\n",
        "        f\"KEYWORDS_{label}\": \",\".join(\n",
        "            set([ent[\"text\"].lower() for ent in row.entities if ent[\"label\"] == label])\n",
        "        )\n",
        "        for label in [\"IX_IMPACT\", \"IX_PRODUCT\", \"IX_BANLIST\"]\n",
        "    }\n",
        "    par_row |= {\n",
        "        f\"PRED_{cls.upper()}\": row.predictions[cls]\n",
        "        for cls in [\"domain\", \"sustainability_potential\", \"financial_tone\"]\n",
        "    }\n",
        "    par_row |= {\n",
        "        f\"X_{cls.upper()}\": \"\"\n",
        "        for cls in [\"domain\", \"sustainability_potential\", \"financial_tone\"]\n",
        "    }\n",
        "    rows.append(par_row)\n",
        "\n",
        "    for i, (predictions, sentence) in enumerate(\n",
        "        zip(row.sentence_predictions, row.sentences)\n",
        "    ):\n",
        "        sent_row = {\n",
        "            \"ID\": row.id,\n",
        "            \"N_KEYWORDS/TOKEN\": row.n_key_tok,\n",
        "            \"PAR_IND\": row.par_ind,\n",
        "            \"SENT_IND\": i,\n",
        "            \"SENT\": sentence,\n",
        "        }\n",
        "        sent_row |= {\n",
        "            f\"KEYWORDS_{label}\": \",\".join(\n",
        "                set(\n",
        "                    [\n",
        "                        ent[\"text\"].lower()\n",
        "                        for ent in row.entities\n",
        "                        if ent[\"label\"] == label and ent[\"sent_ind\"] == i\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "            for label in [\"IX_IMPACT\", \"IX_PRODUCT\", \"IX_BANLIST\"]\n",
        "        }\n",
        "        sent_row |= {\n",
        "            f\"PRED_{cls.upper()}\": predictions.get(cls, \"\")\n",
        "            for cls in [\"domain\", \"sustainability_potential\", \"financial_tone\"]\n",
        "        }\n",
        "        sent_row |= {\n",
        "            cls.upper(): \"\"\n",
        "            for cls in [\"domain\", \"sustainability_potential\", \"financial_tone\"]\n",
        "        }\n",
        "        rows.append(sent_row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COLUMNS = [\n",
        "    \"SCRAPER\",\n",
        "    \"ID\",\n",
        "    \"PAR_IND\",\n",
        "    \"N_KEYWORDS/TOKEN\",\n",
        "    \"SENT_IND\",\n",
        "    \"KEYWORDS_IX_IMPACT\",\n",
        "    \"KEYWORDS_IX_PRODUCT\",\n",
        "    \"KEYWORDS_IX_BANLIST\",\n",
        "    \"PRED_DOMAIN\",\n",
        "    \"PRED_SUSTAINABILITY_POTENTIAL\",\n",
        "    \"PRED_FINANCIAL_TONE\",\n",
        "    \"DOMAIN\",\n",
        "    \"SUSTAINABILITY_POTENTIAL\",\n",
        "    \"FINANCIAL_TONE\",\n",
        "    \"SENT\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labeling_df = pd.DataFrame(rows, columns=COLUMNS)\n",
        "labeling_df.to_csv(OUT_PATH, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labeling_df.sort_values(['N_KEYWORDS/TOKEN', 'ID', 'SENT_IND'], ascending=[False, True, True]).iloc[:100].to_csv(OUT_PATH.with_name(OUT_PATH.stem + \"_sorted.csv\"), sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labeling_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "50ef1f00e07f65fb8c66231f14f6a624080f70ef226807e0f66598eceb63f363"
    },
    "kernelspec": {
      "display_name": "Python 3.9.9 64-bit ('smart-evidence-0MftrBAc-py3.9': poetry)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
