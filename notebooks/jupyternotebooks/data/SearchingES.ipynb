{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from elasticsearch import helpers\n",
    "import boto3\n",
    "\n",
    "host = 'search-metrics-store-vp6epbqctqfib7zheyo5rgckkm.eu-central-1.es.amazonaws.com' # For example, my-test-domain.us-east-1.es.amazonaws.com\n",
    "region = 'eu-central-1' # e.g. us-west-1\n",
    "\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = helpers.scan(\n",
    "    es,\n",
    "    index=\"metrics-*\",\n",
    "    scroll=\"3m\",\n",
    "    size=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([item['_source'] for item in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-revelation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "srsly.write_jsonl(\n",
    "    \"data/metrics.jsonl\",\n",
    "    df[[\"title\", \"description\", \"identifier\"]].fillna('').rename(\n",
    "        {\"identifier\": \"id\", \"description\": \"text\"}\n",
    "    , axis=1).to_dict('records'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.nounchunker import get_nounchunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    min_df=5,\n",
    "    max_df=10,\n",
    "    ngram_range=(1, 3),\n",
    "    #                              vocabulary=list(noun_chunks),\n",
    "    preprocessor=lambda x: x.lower(),\n",
    "    stop_words=\"english\",\n",
    "    token_pattern=r\"(?u)\\b[A-Za-z]\\w+\\b\",\n",
    "    sublinear_tf=True,\n",
    "    smooth_idf=True,\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(\n",
    "    get_nounchunks(df.title[~df.title.isna()])\n",
    ")\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "print(vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for word in words:\n",
    "    if not any([word in other_word for other_word in words if word != other_word]):\n",
    "        vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-community",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.set_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge text fields\n",
    "text_series = df.title + '. ' + df.subtitle + '. ' + df.description + '. ' + df['Human rights issue'] + '. ' + df['SDG indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_series[~text_series.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-ethnic",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "noun_chunks = set()\n",
    "for doc in nlp.pipe(text_series):\n",
    "    for noun in doc.noun_chunks:\n",
    "        if not all([re.match(r'[A-Za-z]\\w+', tok.text) for tok in noun]):\n",
    "            continue\n",
    "        \n",
    "        # strip morphology from single words\n",
    "        if len(noun) == 1:\n",
    "            text = noun.lemma_\n",
    "        # strip plural from noun chunks\n",
    "        elif noun[-1].text.strip(noun[-1].lemma_) == 's':\n",
    "            text = noun.text[:-1].lower()\n",
    "        # always lower\n",
    "        else:\n",
    "            text = noun.text.lower()\n",
    "        noun_chunks.add(text)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in nlp(text_series.iloc[0]):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../textcat_demo/configs/config.cfg') as f:\n",
    "    config = Config().from_str(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-samoa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyairtable import Table\n",
    "from pyairtable.formulas import match\n",
    "api_key = 'keyN3wfCJD6wMCAMA'\n",
    "base_id = 'appGSJaOzNaIZ4lSm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Table(api_key, base_id, \"Key Info\")\n",
    "formula = match({\"Name\": \"Carbon Instead UG (v0.2)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "venture_keyinfo_row = table.first(formula=\"{Assessment/Venture}='Green Fusion'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "venture_keyinfo_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for key, value in venture_keyinfo_row['fields'].items():\n",
    "    if key not in ['Market/sector', 'IRIS impact categories', 'Headquarter', 'Venture in one sentence', 'Mission/Vision/Purpose statement',\n",
    "                  'Inputs - Value Chain', 'Activities - Value Chain', 'Outputs - Value Chain', 'Assessment/Primary SDGs Rollup']:\n",
    "        continue\n",
    "    if type(value) == list:\n",
    "        values += value\n",
    "    elif '\\n' in value:\n",
    "        values += [v.strip().strip('- ') for v in value.split('\\n') if v.strip() != '']\n",
    "    else:\n",
    "        values += [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_nouns = list(nlp(\"Do you measure GHG emissions generated directly or indirectly by your organisation?\").noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "[n.lemma_ for n in question_nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\"terms\": {\n",
    "                    \"title\": [v.lower() for v in values],\n",
    "                    \"boost\": 1.0\n",
    "                }},\n",
    "                {\"terms\": {\n",
    "                    \"title\": [n.lemma_ for n in question_nouns],\n",
    "                    \"boost\": 10.0\n",
    "                }}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = es.search(query, 'metrics-*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([r['_source'] | {'_score': r['_score']} for r in results['hits']['hits']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "html = df[['title', '_score']].to_html()\n",
    "display(HTML(html))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72e5c414fa685c04be857c4b405d4059aa1da4000f4059e821b345d549630a65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
