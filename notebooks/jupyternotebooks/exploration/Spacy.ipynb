{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.chdir('../..')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import spacy\n",
                "\n",
                "# this is any existing model\n",
                "nlp = spacy.blank('en')\n",
                "# nlp = spacy.load('en_ix_entity_ruler')\n",
                "# add the pipeline stage\n",
                "nlp.add_pipe('dbpedia_spotlight', config={\"confidence\": 0.35, 'dbpedia_rest_endpoint': 'http://172.17.0.1:2222/rest'})\n",
                "# see the pipeline, the added stage is at the end\n",
                "print(nlp.pipe_names)\n",
                "# ['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer', 'dbpedia_spotlight']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text = \"\"\"\n",
                "Construction industry is the largest producer of materials when compared with any other industrial\n",
                "sector. Currently the annual production of cement is about 3 billion tonnes and burnt clay bricks are\n",
                "about 3.5 billion tonnes. Consumption of every tonne of cement requires 5 – 6 tonnes of aggregates\n",
                "and therefore 15 – 20 billion tonnes of aggregates are consumed annually. Therefore, Manufacturing\n",
                "and use of construction materials necessitates consumption of raw material resources and energy. Raw\n",
                "materials are mined from the earth and energy is expended to convert these raw materials into\n",
                "construction products. The consequences are depletion of the raw material resources due to mining.\n",
                "Any activity related with mining is unsustainable. Expenditure of energy causes green house gas\n",
                "(GHG) emissions. Thus construction sector has two problems to address: (1) unsustainable mining of\n",
                "limited raw material resources and (2) GHG emissions. It has been assessed that the built environment\n",
                "alone consumes 30% of raw materials extracted and 40% energy resources. The built environment is\n",
                "responsible for 40% of GHG emissions and 30% of solid waste generation. Majority of the arguments\n",
                "proposed regarding sustainability of construction sector in general and the built environment in\n",
                "particular address the issue of pollution and GHG emission reductions. Without addressing the issue\n",
                "of depleting material resources due to mining there is no meaning in talking about sustainability of\n",
                "construction sector. This presentation will discuss some real issues of sustainability with reference to\n",
                "construction sector and the technology of stabilised soil products (low energy and sustainable\n",
                "products) for structural applications like walls and other building components.\n",
                "Concepts of sustainability of construction sector particularly with reference to the mining of material\n",
                "resources and energy represent the main focus of the presentation. Energy, emissions and life cycle of\n",
                "some conventional materials are discussed. Case studies of zero carbon foot print vernacular\n",
                "structures and the problems associated with rating systems are illustrated. Broad guidelines on\n",
                "achieving sustainability construction sector are proposed.\n",
                "Potential of earth based low embodied carbon building products for structural applications in\n",
                "buildings has been illustrated with some examples. Loss of strength on saturation and rain erosion are\n",
                "the two major disadvantages of pure soil based constructions. Hence, there is a need for stabilised soil\n",
                "products for structural components of buildings. Examples of centuries old earthen structures\n",
                "especially multi-storey residential structures are pictorially illustrated. Surge of recent interests in\n",
                "reviving earthen architecture for dwellings with case studies are shown.\n",
                "Principles soil stabilisation as adopted for the production of stabilised soil blocks and stabilised\n",
                "rammed earth elements would be dealt in greater detail. Density, strength and moisture relationships\n",
                "and their importance in devising good quality stabilised soil blocks and stabilised rammed earth walls\n",
                "forms the main theme of discussions on stabilised soil products for structural applications.\n",
                "Discussions on embodied carbon in stabilised soil products, retrieving clay minerals from such\n",
                "products, recycling and end of life considerations of such products forms the main scientific analysis.\n",
                "The presentation leads to the emergence of some useful guidelines on stabilised earth construction as\n",
                "applicable to sustainable constructions\n",
                "\"\"\"\n",
                "\n",
                "doc = nlp(text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from smart_evidence.models.knowledgebase import ImpactCategory, ImpactConcept\n",
                "# impact_concepts = ImpactConcept.nodes.all()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "impact_concept_dbpedia_ids = [ic.dbpedia_id for ic in impact_concepts]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[(ent.label_, ent.kb_id_, ent.id_, ent.start) for ent in list(doc.ents) + list(doc.spans.get('dbpedia_spotlight', [])) + list(doc.spans.get('ents_original', [])) if ent.label_ == 'COMPANY' or ent.kb_id_ in impact_concept_dbpedia_ids]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "list(Path('assets/keywords_raw/Impact/IRIS_dbpedoa').rglob('**/IMPACT.tsv'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "for keyword_file_path in Path('assets/keywords_raw/Impact/IRIS_dbpedoa/').rglob('**/IMPACT.tsv'):\n",
                "    ents = []\n",
                "    with open(keyword_file_path, 'rt', encoding='utf8') as f:\n",
                "        print('======================')\n",
                "        print(keyword_file_path)\n",
                "        for doc in nlp.pipe(line.strip() for line in f if not (not line.strip() or line.startswith('https') or line.startswith('#') or line.startswith('dbr:') or line.startswith('dbc:'))):\n",
                "            ents.extend(doc.ents)\n",
                "    with open(str(keyword_file_path), 'wt', encoding='utf8') as f:\n",
                "        f.write('\\n'.join({ent.kb_id_ for ent in ents}))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text = '''\n",
                "In highly regulated developed countries, industrial wastewater usually receives at least pretreatment if not full treatment at the factories themselves to reduce the pollutant load, before discharge to the sewer. The pretreatment has the following aims: to remove constituents that may pose risks to the sewerage system and its workers; prevent toxic or inhibitory compounds to the microorganisms in the biological stage in the municipal treatment plant; hinder beneficial use of the produced sewage sludge; or that will still be present in the final effluent from the treatment plant.: 59  Some industrial wastewater may contain pollutants which cannot be removed by sewage treatment plants. Also, variable flow of industrial waste associated with production cycles may upset the population dynamics of biological treatment units.\t\n",
                "'''\n",
                "[(ent.start, ent.end, ent.start_char, ent.text, ent.kb_id_, ent.label_) for ent in nlp(text).ents]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text[46:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text = '''\n",
                "As regards waste management, the acquis has not yet been fully transposed. Legislation is still required on waste and packaging. Transposition of the recent acquis on end-of-life vehicles also needs to be completed. Certain regional and local waste management programmes need to be improved. Implementing regulations on hazardous waste, on the list of waste for recycling and disposal, packaging, excise duties on packaging and the Basle Convention have been adopted. Progress continues on the setting up of the network of waste elimination plants. Waste disposal sites have been put into operation or reconstructed. Two regulations have been adopted on the manufacture of packaging and metal waste. Other regulations have been adopted regarding asbestos waste, waste reporting, the national packaging information system, shipment of waste, hazardous waste and the EC waste catalogue. Administrative capacity in this area needs to be stepped up at regional and central level. As regards landfill of waste, a transitional arrangement lasting until 2009 has been agreed for oil shale.\t\n",
                "'''\n",
                "[(ent.kb_id_, ent) for ent in nlp(text).ents]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text = '''\n",
                "Steel and aluminum are key economic sectors for the carbon capture and storage. According to a 2013 study, \"in 2004, the steel industry along emits about 590M tons of CO2, which accounts for 5.2% of the global anthropogenic GHG emissions. CO2 emitted from steel production primarily comes from energy consumption of fossil fuel as well as the use of limestone to purify iron oxides.\" sentences:Steel and aluminum are key economic sectors for the carbon capture and storage., According to a 2013 study, \"in 2004, the steel industry along emits about 590M tons of CO2, which accounts for 5.2% of the global anthropogenic GHG emissions., CO2 emitted from steel production primarily comes from energy consumption of fossil fuel as well as the use of limestone to purify iron oxides.\"\n",
                "'''\n",
                "[(ent.kb_id_, ent) for ent in nlp(text).ents]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "our_nlp = spacy.load('en_ix_entity_ruler')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "doc = our_nlp(text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[(ent) for ent in doc.ents if ent.label_ in ['COMPANY', \"IMPACT\"]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "doc = nlp(text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[(ent.kb_id_, ent) for ent in doc.ents]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from spacy.kb import KnowledgeBase\n",
                "vocab = nlp.vocab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from smart_evidence.helpers.concept_patterns import get_concepts_from_yamls"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "def create_kb(vocab):\n",
                "    kb = KnowledgeBase(vocab=vocab, entity_vector_length=64)\n",
                "    concepts = get_concepts_from_yamls(['assets/keywords_clean/COMPANY.yaml', 'assets/keywords_clean/IMPACT.yaml'])\n",
                "\n",
                "    for concept in concepts:\n",
                "        kb.add_entity(entity=concept['concept_label'], freq=1, entity_vector=np.zeros(64))\n",
                "        for keyword in concept['keywords']['en']:\n",
                "            kb.add_alias(alias=keyword, entities=[concept['concept_label']], probabilities=[1.0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from spacy.pipeline.entity_linker import DEFAULT_NEL_MODEL\n",
                "config = {\n",
                "   \"labels_discard\": [],\n",
                "   \"n_sents\": 0,\n",
                "   \"incl_prior\": True,\n",
                "   \"incl_context\": True,\n",
                "   \"model\": DEFAULT_NEL_MODEL,\n",
                "   \"entity_vector_length\": 64,\n",
                "   \"get_candidates\": {'@misc': 'spacy.CandidateGenerator.v1'},\n",
                "}\n",
                "entity_linker = nlp.add_pipe(\"entity_linker\", config=config)\n",
                "entity_linker.set_kb(create_kb)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nlp(text)[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "doc = nlp(text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nlp('hellow')._.trf_data.tensors[-1].mean(0).shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[(ent.text, [tok.tag_ for tok in ent]) for ent in doc.ents]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "doc[0].lemma_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nlp.pipeline[-1][1].add_patterns([{'label': \"COMPANY\", \"pattern\": [{'LEMMA': 'drywall'}]}])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[p for p in nlp.pipeline[-1][1].patterns if 'Drywall' in p['id']] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "doc.ents"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "contents = [\n",
                "    \"PVC is made from fossil fuels, including natural gas. The production process also uses sodium chloride which results in a polymer containing 57% chloride content. Recycled PVC is broken down into small chips, impurities removed, and the product refined to make pure PVC.[37] It can be recycled roughly seven times and has a lifespan of around 140 years.\",\n",
                "    \"The combination of the two prefabricated construction systems, applied on the case study, allowed the reduction of the building energy demand by 82%.\",\n",
                "    \"However, only about 1% of all polypropylene in the world is actually recycled.\",\n",
                "    'When managed and aligned well with the existing business quality systems, A.I. helps manufacturing companies achieve their sustainability goals within a specified time while ensuring operational and compliance excellence. It gives them better control and confidence in managing their quality processes. Therefore, A.I. and advanced quality systems make a winning combination for manufacturers.'\n",
                "]\n",
                "\n",
                "for content in contents:\n",
                "    doc = nlp(content)\n",
                "    print([nc.label_ for nc in doc.ents])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "contents = [\n",
                "    \"PVC is made from fossil fuels, including natural gas. The production process also uses sodium chloride which results in a polymer containing 57% chloride content. Recycled PVC is broken down into small chips, impurities removed, and the product refined to make pure PVC.[37] It can be recycled roughly seven times and has a lifespan of around 140 years.\",\n",
                "    \"The combination of the two prefabricated construction systems, applied on the case study, allowed the reduction of the building energy demand by 82%.\",\n",
                "    \"However, only about 1% of all polypropylene in the world is actually recycled.\",\n",
                "    'When managed and aligned well with the existing business quality systems, A.I. helps manufacturing companies achieve their sustainability goals within a specified time while ensuring operational and compliance excellence. It gives them better control and confidence in managing their quality processes. Therefore, A.I. and advanced quality systems make a winning combination for manufacturers.'\n",
                "]\n",
                "\n",
                "for content in contents:\n",
                "    doc = nlp(content)\n",
                "    print([nc for nc in doc.noun_chunks])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "doc.noun_chunks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('results/22-02-22_annotation/Sources 8cbbe.csv', sep=\",\", na_values=[''], keep_default_na=False, index_col=0)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['noun_chunks'] = df.Text.apply(lambda x: list(nlp(x).noun_chunks))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.noun_chunks\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_impact = 0\n",
                "n_company = 0\n",
                "for row in df.itertuples():\n",
                "    try:\n",
                "        company_contepts = row._6.split(', ')\n",
                "    except:\n",
                "        company_contepts = []\n",
                "    try:\n",
                "        impact_concepts = row._7.split(', ')\n",
                "    except:\n",
                "        impact_concepts = []\n",
                "\n",
                "    nounchunks = row.noun_chunks\n",
                "    nc_has_company = any([c_c in nc.text for c_c in company_contepts for nc in nounchunks])\n",
                "    nc_has_impact = any([c_c in nc.text for c_c in impact_concepts for nc in nounchunks])\n",
                "    if nc_has_impact:\n",
                "        n_impact += 1\n",
                "    else:\n",
                "        print(nounchunks, impact_concepts)\n",
                "    if nc_has_company:\n",
                "        n_company += 1\n",
                "    else:\n",
                "        print(nounchunks, company_contepts)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_impact, n_company"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "len(df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "contents[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from smart_evidence.components.concept_context_extractor import ConceptContextExtractor "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "concept_extractor = ConceptContextExtractor()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "concept_extractor.extract(contents[1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "a  = [{'id':1, 'text': 'hello',},{'id':2, 'text': 'world'}]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "b = [i for i in a if i['id'] == 1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "b[0]['text'] = 'world'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "a"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import spacy\n",
                "nlp = spacy.load('en_core_web_trf_based_keyword_ruler')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[ent.ent_id_ for ent in nlp('Cement has large emissions.').ents]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import dotenv\n",
                "from playhouse.db_url import connect\n",
                " \n",
                "\n",
                "dotenv.load_dotenv()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "psql_db.connect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.chdir('../..')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pwd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.environ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "db = connect(\n",
                "    db_id=\"mysql\",\n",
                "    db_settings={\n",
                "        \"user\": os.environ[\"POSTGRES_USER\"],\n",
                "        \"password\": os.environ[\"POSTGRES_PASS\"],\n",
                "        \"host\": os.environ[\"POSTGRES_HOST\"],\n",
                "        \"port\": 3306,\n",
                "        \"database\": os.environ[\"POSTGRES_DB\"],\n",
                "        \"ssl\": {\"ssl\": {\"ssl-ca\": \"server-ca.pem\"}},\n",
                "    },\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import spacy\n",
                "nlp = spacy.load('en_ix_entity_ruler')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[(ent, ent.ent_id_, ent.label_) for ent in nlp('Researchers at University of Auckland are working on utilizing biochar in concrete applications to reduce carbon emissions during concrete production and to improve strength.').ents]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.12 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}