{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraphs_generator(glob_path='corpus/new-paragraphs/*.jsonl'):\n",
    "    for file_path in glob(glob_path):\n",
    "        yield from srsly.read_jsonl(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_TRANSLATOR = {\n",
    "    # \"POSITIVE_CONTRADICTION\": \"POSITIVE\",\n",
    "    # \"NEGATIVE_CONTRADICTION\": \"NEGATIVE\",\n",
    "    \"POSITIVE\": \"POSITIVE\",\n",
    "    \"NEGATIVE\": \"NEGATIVE\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import OpenSearchDocumentStore\n",
    "from smart_evidence.helpers import opensearch_connection\n",
    "from opensearchpy.helpers import scan\n",
    "\n",
    "def paragraphs_generator(index=\"paragraphs\"):\n",
    "    document_store = OpenSearchDocumentStore(\n",
    "        username=\"admin\",\n",
    "        password=\"R9$Cix3vD$BU#z\",\n",
    "        host=opensearch_connection.HOST,\n",
    "        port=443,\n",
    "        timeout=60,\n",
    "        aws4auth=opensearch_connection.AWS_AUTH,\n",
    "        verify_certs=True,\n",
    "        index=index,\n",
    "        label_index=\"haystack-paragraphs-labels\",\n",
    "        search_fields=[\"text\", \"title\"],\n",
    "        similarity=\"cosine\",\n",
    "        content_field=\"text\",\n",
    "        name_field=\"title\",\n",
    "        analyzer=\"english\",\n",
    "        duplicate_documents=\"skip\",\n",
    "    )\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must_not\": [\n",
    "                    {\n",
    "                        \"nested\": {\n",
    "                            \"path\": \"concept_relations\",\n",
    "                            \"query\": {\"exists\": {\"field\": \"concept_relations.LABEL\"}},\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    items = scan(\n",
    "        document_store.client,\n",
    "        query=body,\n",
    "        index=index,\n",
    "        size=1000,\n",
    "        scroll=\"5m\",\n",
    "    )\n",
    "\n",
    "    items = (\n",
    "        document_store._convert_es_hit_to_document(item, return_embedding=False)\n",
    "        for item in items\n",
    "    )\n",
    "    yield from (d.to_dict() for d in document_store.get_all_documents_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_evidence.helpers.concept_patterns import get_concepts_from_yamls\n",
    "\n",
    "def create_cooccurrence_matrix(paragraphs):\n",
    "    \"\"\"Create co occurrence matrix from given list of annotated paragraphs.\n",
    "\n",
    "    Returns:\n",
    "    - company vocabs: dictionary of company concept counts\n",
    "    - impact vocabs: dictionary of impact concept counts\n",
    "    - co_occ_matrix_sparse: sparse co occurrence matrix\n",
    "\n",
    "    Example:\n",
    "    ===========\n",
    "    vocabs,co_occ = create_cooccurrence_matrix(sentences)\n",
    "\n",
    "    df_co_occ  = pd.DataFrame(co_occ.todense(),\n",
    "                              index=vocabs.keys(),\n",
    "                              columns = vocabs.keys())\n",
    "\n",
    "    df_co_occ = df_co_occ.sort_index()[sorted(vocabs.keys())]\n",
    "\n",
    "    df_co_occ.style.applymap(lambda x: 'color: red' if x>0 else '')\n",
    "\n",
    "    \"\"\"\n",
    "    import scipy\n",
    "\n",
    "    company_vocabulary = {}\n",
    "    impact_vocabulary = {}\n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "    impact_concepts = {k['concept_label']: k['id'] for k in get_concepts_from_yamls(['assets/keywords_clean/IMPACT.yaml'])}\n",
    "    company_concepts = {k['concept_label']: k['id'] for k in get_concepts_from_yamls(['assets/keywords_clean/COMPANY.yaml']) } \n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        sentence_predictions = paragraph['meta'].get('concept_relations', [])\n",
    "        for sentence_prediction in sentence_predictions:\n",
    "            if sentence_prediction['LABEL'] not in LABEL_TRANSLATOR.keys(): continue\n",
    "            if 'company_concept' not in sentence_prediction: continue\n",
    "            \n",
    "            label = LABEL_TRANSLATOR[sentence_prediction['LABEL']]\n",
    "            \n",
    "            company_concept_label = sentence_prediction['company_concept']['concept_label']\n",
    "            if company_concept_label not in company_concepts:\n",
    "                continue\n",
    "            company_concept_id = company_concepts[company_concept_label] + f\"|{label}\"\n",
    "            \n",
    "            impact_concept_label = sentence_prediction['impact_concept']['concept_label']\n",
    "            if impact_concept_label not in impact_concepts:\n",
    "                continue\n",
    "            impact_concept_id = impact_concepts[impact_concept_label]\n",
    "\n",
    "            i = company_vocabulary.setdefault(company_concept_id, len(company_vocabulary))\n",
    "            j = impact_vocabulary.setdefault(impact_concept_id, len(impact_vocabulary))\n",
    "            data.append(1)\n",
    "            row.append(i)\n",
    "            col.append(j)\n",
    "\n",
    "    cooccurrence_matrix_sparse = scipy.sparse.coo_matrix((data, (row, col)))\n",
    "    return company_vocabulary, impact_vocabulary, cooccurrence_matrix_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_vocabulary, impact_vocabulary, cooccurrence_matrix_sparse = create_cooccurrence_matrix(paragraphs_generator('paragraphs_v4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(company_vocabulary), len(impact_vocabulary), cooccurrence_matrix_sparse.shape, cooccurrence_matrix_sparse.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` py\n",
    "# 4.4.2022\n",
    "len(company_vocabulary), len(impact_vocabulary), cooccurrence_matrix_sparse.shape\n",
    "> (1157, 211, (1157, 211))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` py\n",
    "# 9.5.2022\n",
    "len(company_vocabulary), len(impact_vocabulary), cooccurrence_matrix_sparse.shape\n",
    "> (3945, 236, (3945, 236))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` py\n",
    "# 17.5.2022\n",
    "len(company_vocabulary), len(impact_vocabulary), cooccurrence_matrix_sparse.shape\n",
    "> (3431, 223, (3431, 223))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` py\n",
    "# 24.5.2022\n",
    "len(company_vocabulary), len(impact_vocabulary), cooccurrence_matrix_sparse.shape\n",
    "> (3305, 375, (3305, 375))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` py\n",
    "# 25.5.2022\n",
    "len(company_vocabulary), len(impact_vocabulary), cooccurrence_matrix_sparse.shape\n",
    "> (3060, 360, (3060, 360), 309127)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` py\n",
    "# 02.06.2022\n",
    "len(company_vocabulary), len(impact_vocabulary), cooccurrence_matrix_sparse.shape\n",
    "> (3235, 361, (3235, 361), 425382)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import date\n",
    "with open(f'cooccurance_{date.today().strftime(\"%Y-%m-%d\")}.pickle', 'bw') as f:\n",
    "    pickle.dump((company_vocabulary, impact_vocabulary, cooccurrence_matrix_sparse.todense()), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "latest_file = sorted(glob('cooccurance_*.pickle'))[-1]\n",
    "with open(latest_file, 'br') as f:\n",
    "    company_vocabulary, impact_vocabulary, cooccurrence_matrix_sparse = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(vocab, ind) for vocab, ind in company_vocabulary.items() if 'Isenheim' in vocab.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(company_vocabulary), len(impact_vocabulary), cooccurrence_matrix_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_cooccurance_df(file_path=\"cooccurance-2022-05-09.pickle\") -> pd.DataFrame:\n",
    "    with open(file_path, \"br\") as f:\n",
    "        company_vocabulary, impact_vocabulary, cooccurrence_matrix_sparse = pickle.load(\n",
    "            f\n",
    "        )\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        cooccurrence_matrix_sparse,\n",
    "        index=company_vocabulary.keys(),\n",
    "        columns=impact_vocabulary.keys(),\n",
    "    )\n",
    "\n",
    "    columns = list(df.columns)\n",
    "    for id in columns:\n",
    "        if id.count(\";\") > 1:\n",
    "            parts = id.split(\";\")\n",
    "            concept_label = parts[-1]\n",
    "            taxonomies = parts[:-1]\n",
    "            for taxonomy in taxonomies:\n",
    "                df[f\"{taxonomy};{concept_label}\"] = df[id]\n",
    "            df = df.drop(columns=id)\n",
    "\n",
    "    indices = list(df.index)\n",
    "    for id in indices:\n",
    "        if id.count(\";\") > 1:\n",
    "            parts = id.split(\";\")\n",
    "            concept_label = parts[-1]\n",
    "            taxonomies = parts[:-1]\n",
    "            for taxonomy in taxonomies:\n",
    "                df.loc[f\"{taxonomy};{concept_label}\"] = df.loc[id]\n",
    "            df = df.drop(index=id)\n",
    "\n",
    "    def turn_string_to_multi(index):\n",
    "        parts = re.split('[\\|\\/]', index)\n",
    "        indices = []\n",
    "        for part in parts:\n",
    "            if len(parts) != 6 and part in [\"COMPANY\"]:\n",
    "                indices += [\"\"] * (6 - len(parts))\n",
    "            indices.append(part.strip())\n",
    "        return tuple(indices)\n",
    "\n",
    "    df.columns = pd.MultiIndex.from_tuples([re.split(r'[\\|\\/]', col) for col in df.columns])\n",
    "\n",
    "    df.index = pd.MultiIndex.from_tuples(\n",
    "        [turn_string_to_multi(ind) for ind in df.index]\n",
    "    )\n",
    "\n",
    "    df.style.applymap(lambda x: \"color: red\" if x > 0 else \"\")\n",
    "\n",
    "    df = df.iloc[:, np.argsort(-df.sum(0).values)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_cooccurance_df('cooccurance_2022-06-02.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0a532144255747c9fc026cc5fe041066dd2136635c93ea916b266688de6dfd4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('smart-evidence-My4wO2kg-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
